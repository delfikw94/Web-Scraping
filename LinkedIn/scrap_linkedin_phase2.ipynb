{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkedIn Scrapping phase 2 (Scrap the Company Profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging In LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-591521968f4e>:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\ddeel\\Local\\chromedriver.exe\", chrome_options=chrome_options)\n",
      "<ipython-input-2-591521968f4e>:5: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\ddeel\\Local\\chromedriver.exe\", chrome_options=chrome_options)\n",
      "<ipython-input-2-591521968f4e>:11: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  elementID = driver.find_element_by_id(\"username\")\n",
      "<ipython-input-2-591521968f4e>:15: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  elementID = driver.find_element_by_id(\"password\")\n",
      "<ipython-input-2-591521968f4e>:19: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  sign_in_button = driver.find_element_by_xpath('//*[@type=\"submit\"]')\n"
     ]
    }
   ],
   "source": [
    "# Setting browser\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "#Change the path where you put the chromedriver.exe\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\ddeel\\Local\\chromedriver.exe\", chrome_options=chrome_options)\n",
    "\n",
    "# Masuk LinkedIn, login\n",
    "driver.get(\"https://www.linkedin.com/login\")\n",
    "\n",
    "# Masukkan Username\n",
    "elementID = driver.find_element_by_id(\"username\")\n",
    "elementID.send_keys('delfikw94@gmail.com') # email/username linkedin here\n",
    "\n",
    "# Masukkan password\n",
    "elementID = driver.find_element_by_id(\"password\")\n",
    "elementID.send_keys('Jazzd31fy') # linkedin password here\n",
    "\n",
    "# Submit dengan click button\n",
    "sign_in_button = driver.find_element_by_xpath('//*[@type=\"submit\"]')\n",
    "sign_in_button.click()\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat list untuk menampung hasil scraping\n",
    "name = []\n",
    "description = []\n",
    "tipe = []\n",
    "websites = []\n",
    "size = []\n",
    "hq = []\n",
    "founded = []\n",
    "specialties = []\n",
    "address = []\n",
    "industries = []\n",
    "employee = []\n",
    "compUrl = []\n",
    "phones = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bibit.id</td>\n",
       "      <td>https://www.linkedin.com/company/bibit/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pegipegi</td>\n",
       "      <td>https://www.linkedin.com/company/pegipegi/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company Name                                        Link\n",
       "0     Bibit.id     https://www.linkedin.com/company/bibit/\n",
       "1     Pegipegi  https://www.linkedin.com/company/pegipegi/"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe from the recent output file\n",
    "# file inputan bisa diganti dengan file 'output.xlsx'\n",
    "# pastikan jumlah link profile company yang akan diiterasi maksimum 200\n",
    "data = pd.read_excel('test.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.linkedin.com/company/bibit/',\n",
       " 'https://www.linkedin.com/company/pegipegi/']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Membaca file xlsx dan memasukkan nilainya ke dalam list\n",
    "urls = []\n",
    "for i in range(len(data)): # atau bisa ditulis range(200)\n",
    "    urls.append(data['Link'][i])\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(urls)):\n",
    "    url = urls[i]\n",
    "    driver.get(url+'/about/')\n",
    "    try:\n",
    "        nama = WebDriverWait(driver, 5).until(EC.presence_of_element_located((\n",
    "            By.CSS_SELECTOR, \"div[class='block mt2']>div>h1\"))).text\n",
    "        name.append(nama)\n",
    "    except:\n",
    "        pass\n",
    "    sleep(2)\n",
    "    try:\n",
    "        desc = WebDriverWait(driver, 5).until(EC.presence_of_element_located((\n",
    "            By.CSS_SELECTOR, \"h4[class='text-heading-large mb4']+p\"))).text\n",
    "        description.append(desc)\n",
    "    except:\n",
    "        pass\n",
    "        description.append(\"\")\n",
    "    sleep(2)\n",
    "    all = driver.find_element(By.CSS_SELECTOR, \"dl[class='overflow-hidden']\").text\n",
    "    try:\n",
    "        Type = all.split('Type')[1].strip().split('\\n')[0].strip()\n",
    "        tipe.append(Type)\n",
    "    except:\n",
    "        pass\n",
    "        tipe.append(\"\")\n",
    "    sleep(2)\n",
    "    try:\n",
    "        ind = all.split('Industry')[1].strip().split('\\n')[0].strip()\n",
    "        industries.append(ind)\n",
    "    except:\n",
    "        pass\n",
    "        industries.append(\"\")\n",
    "    sleep(2)\n",
    "    try:\n",
    "        sp = all.split('Specialties')[1].strip().split('\\n')[0].strip()\n",
    "        specialties.append(sp)\n",
    "    except:\n",
    "        pass\n",
    "        specialties.append(\"\")\n",
    "    sleep(2)\n",
    "    try:\n",
    "        found = all.split('Founded')[1].strip().split('\\n')[0].strip()\n",
    "        founded.append(found)\n",
    "    except:\n",
    "        pass\n",
    "        founded.append(\"\")\n",
    "    sleep(2)\n",
    "    try:\n",
    "        sz = all.split('Company size')[1].strip().split('\\n')[0].strip()\n",
    "        size.append(sz)\n",
    "    except:\n",
    "        pass\n",
    "        size.append(\"\")\n",
    "    sleep(2)\n",
    "    try:\n",
    "        emp = all.split('Company size')[1].strip().split('\\n')[1].strip().split()[0]\n",
    "        employee.append(emp)\n",
    "    except:\n",
    "        pass\n",
    "        employee.append(\"\")\n",
    "    sleep(2)\n",
    "    try:\n",
    "        head = all.split('Headquarters')[1].strip().split('\\n')[0].strip()\n",
    "        hq.append(head)\n",
    "    except:\n",
    "        pass\n",
    "        hq.append(\"\")\n",
    "    sleep(2)\n",
    "    try:\n",
    "        add = WebDriverWait(driver, 5).until(EC.presence_of_element_located((\n",
    "            By.CSS_SELECTOR, \"h4[class='t-14 t-black--light t-bold mr1 mt1']+p\"))).text\n",
    "        address.append(add)\n",
    "    except:\n",
    "        pass\n",
    "        address.append(\"\")\n",
    "    sleep(2)\n",
    "    try:\n",
    "        web = all.split('Website')[1].strip().split('\\n')[0].strip()\n",
    "        websites.append(web)\n",
    "    except:\n",
    "        pass\n",
    "        websites.append(\"\")\n",
    "    sleep(2)\n",
    "    try:\n",
    "        phone = all.split('Phone')[1].strip().split('\\n')[0].strip()\n",
    "        phones.append(phone)\n",
    "    except:\n",
    "        pass\n",
    "        phones.append(\"\")\n",
    "    sleep(2)\n",
    "    compUrl.append(url)\n",
    "    sleep(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for the scrap result\n",
    "df = pd.DataFrame()\n",
    "df['Company Name'] = name\n",
    "df['Description'] = description\n",
    "df['Type'] = tipe\n",
    "df['Industry'] = industries\n",
    "df['Specialties'] = specialties\n",
    "df['Founded'] = founded\n",
    "df['Company Size'] = size\n",
    "df['Employees on Linkedin'] = employee\n",
    "df['Headquarter'] = hq\n",
    "df['Address'] = address\n",
    "df['Website'] = websites\n",
    "df['Phone'] = phones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Specialties</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Company Size</th>\n",
       "      <th>Employees on Linkedin</th>\n",
       "      <th>Headquarter</th>\n",
       "      <th>Address</th>\n",
       "      <th>Website</th>\n",
       "      <th>Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bibit.id</td>\n",
       "      <td>We are a startup company with a mission to inc...</td>\n",
       "      <td></td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>technology, mutual funds, robo-advisor, financ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>201-500 employees</td>\n",
       "      <td>484</td>\n",
       "      <td>Setiabudi, Jakarta</td>\n",
       "      <td>Jalan Prof. Dr. Satrio, Setiabudi, Jakarta 129...</td>\n",
       "      <td>http://Bibit.id</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pegipegi</td>\n",
       "      <td>Pegipegi is one of the most renowned online tr...</td>\n",
       "      <td></td>\n",
       "      <td>Leisure, Travel &amp; Tourism</td>\n",
       "      <td>hotel reservation, promotion packages, and tra...</td>\n",
       "      <td>2012</td>\n",
       "      <td>201-500 employees</td>\n",
       "      <td>280</td>\n",
       "      <td>Jakarta, DKI Jakarta</td>\n",
       "      <td>Jl. Raya Perjuangan No. 23 Kebon Jeruk, Jakart...</td>\n",
       "      <td>https://www.pegipegi.com/</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company Name                                        Description Type  \\\n",
       "0     Bibit.id  We are a startup company with a mission to inc...        \n",
       "1     Pegipegi  Pegipegi is one of the most renowned online tr...        \n",
       "\n",
       "                    Industry  \\\n",
       "0         Financial Services   \n",
       "1  Leisure, Travel & Tourism   \n",
       "\n",
       "                                         Specialties Founded  \\\n",
       "0  technology, mutual funds, robo-advisor, financ...    2019   \n",
       "1  hotel reservation, promotion packages, and tra...    2012   \n",
       "\n",
       "        Company Size Employees on Linkedin           Headquarter  \\\n",
       "0  201-500 employees                   484    Setiabudi, Jakarta   \n",
       "1  201-500 employees                   280  Jakarta, DKI Jakarta   \n",
       "\n",
       "                                             Address  \\\n",
       "0  Jalan Prof. Dr. Satrio, Setiabudi, Jakarta 129...   \n",
       "1  Jl. Raya Perjuangan No. 23 Kebon Jeruk, Jakart...   \n",
       "\n",
       "                     Website Phone  \n",
       "0            http://Bibit.id        \n",
       "1  https://www.pegipegi.com/        "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show result of dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddeel\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:123: UserWarning: Pandas requires version '1.0.2' or newer of 'xlsxwriter' (version '0.7.3' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Export the scrap result into xlsx file\n",
    "df.to_excel('result.xlsx')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adf0d0f455a2e4970ec8799375c42b2723a3fed26b97e4246df55536fe16de4e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
